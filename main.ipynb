{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Huffman Encoding & Side Information Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Vector{String}:\n",
       " \"A\"\n",
       " \"B\"\n",
       " \"C\"\n",
       " \"D\"\n",
       " \"E\"\n",
       " \"I\"\n",
       " \"α\"\n",
       " \"β\"\n",
       " \"γ\"\n",
       " \"δ\"\n",
       " \"ϵ\"\n",
       " \"ϕ\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "english::Vector{String} = [\"A\", \"B\", \"C\", \"D\", \"E\", \"I\"];\n",
    "greek::Vector{String} = [\"α\", \"β\", \"γ\", \"δ\", \"ϵ\", \"ϕ\"];\n",
    "alphabets::Vector{String} = [];\n",
    "\n",
    "append!(alphabets, english)\n",
    "append!(alphabets, greek)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Probability Mass Function of each alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 12 entries:\n",
       "  \"C\" => 1//18\n",
       "  \"ϵ\" => 1//12\n",
       "  \"δ\" => 1//12\n",
       "  \"B\" => 1//18\n",
       "  \"A\" => 1//9\n",
       "  \"ϕ\" => 1//12\n",
       "  \"D\" => 1//18\n",
       "  \"α\" => 1//12\n",
       "  \"E\" => 1//9\n",
       "  \"γ\" => 1//12\n",
       "  \"I\" => 1//9\n",
       "  \"β\" => 1//12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = Dict();\n",
    "for alphabet in alphabets\n",
    "    if string(alphabet) ∈ greek\n",
    "        P[alphabet] = 1 // 12;\n",
    "    elseif string(alphabet) ∈ [\"A\", \"E\", \"I\"]\n",
    "        P[alphabet] = 1 // 9;\n",
    "    else\n",
    "        P[alphabet] = 1 // 18;\n",
    "    end\n",
    "end\n",
    "\n",
    "P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Block Coding, followed by Huffman Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./block_code.jl\")\n",
    "include(\"./tools.jl\")\n",
    "\n",
    "# Sort Symbols and Probabilities & Create Block Codes\n",
    "sorted_probabilities, sorted_symbols, P_sorted_dict = sort_prob(P);\n",
    "block2_codes, prob_block2_codes = create_block_coding(sorted_symbols, sorted_probabilities, 2);\n",
    "block3_codes, prob_block3_codes = create_block_coding(sorted_symbols, sorted_probabilities, 3);\n",
    "\n",
    "prob_block2_codes, block2_codes, P2_sorted_dict = sort_prob(prob_block2_codes, block2_codes);\n",
    "prob_block3_codes, block3_codes, P3_sorted_dict = sort_prob(prob_block3_codes, block3_codes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: syntax: invalid escape sequence\nin expression starting at /Users/odas2/Documents/ece159_project/huffman.jl:111",
     "output_type": "error",
     "traceback": [
      "LoadError: syntax: invalid escape sequence\n",
      "in expression starting at /Users/odas2/Documents/ece159_project/huffman.jl:111\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/ece159_project/huffman.jl:111"
     ]
    }
   ],
   "source": [
    "include(\"./huffman.jl\")\n",
    "\n",
    "huffman_tree = construct_huffman_tree(P_sorted_dict);\n",
    "huffman2_tree = construct_huffman_tree(P2_sorted_dict);\n",
    "huffman3_tree = construct_huffman_tree(P3_sorted_dict);\n",
    "\n",
    "encoder1 = Dict();\n",
    "encoder2 = Dict();\n",
    "encoder3 = Dict();\n",
    "\n",
    "build_encoder(huffman_tree, \"\", encoder1);\n",
    "build_encoder(huffman2_tree, \"\", encoder2);\n",
    "build_encoder(huffman3_tree, \"\", encoder3);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1a) Huffman Encoder and its Expected length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 12 entries:\n",
       "  \"C\" => \"1000\"\n",
       "  \"ϵ\" => \"1011\"\n",
       "  \"δ\" => \"1100\"\n",
       "  \"B\" => \"1001\"\n",
       "  \"A\" => \"001\"\n",
       "  \"ϕ\" => \"1101\"\n",
       "  \"D\" => \"1010\"\n",
       "  \"α\" => \"1110\"\n",
       "  \"E\" => \"010\"\n",
       "  \"γ\" => \"1111\"\n",
       "  \"I\" => \"011\"\n",
       "  \"β\" => \"000\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huffman Encoder with block length 1 has expected length 3.5833333333333335 bits\n",
      "Huffman Encoder with block length 2 has expected length 7.114197530864198 bits\n",
      "Huffman Encoder with block length 3 has expected length 10.664566186556927 bits\n"
     ]
    }
   ],
   "source": [
    "function report_expected_len(encoder, P, n)\n",
    "    len = expected_length(encoder, P);\n",
    "    len = float(len)\n",
    "    println(\"Huffman Encoder with block length $n has expected length $(len) bits\")\n",
    "end\n",
    "\n",
    "report_expected_len(encoder1, P_sorted_dict, 1)\n",
    "report_expected_len(encoder2, P2_sorted_dict, 2)\n",
    "report_expected_len(encoder3, P3_sorted_dict, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcmillan_inequality(encoder1)\n",
    "# mcmillan_inequality(encoder2)\n",
    "# mcmillan_inequality(encoder3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Side Information Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_dict = Dict();\n",
    "for alphabet in alphabets\n",
    "    if alphabet ∈ english\n",
    "        language_dict[alphabet] = \"e\";\n",
    "    elseif alphabet ∈ greek\n",
    "        language_dict[alphabet] = \"g\";\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 1728 entries:\n",
       "  \"DBϵ\" => \"eeg\"\n",
       "  \"IϕC\" => \"ege\"\n",
       "  \"DβI\" => \"ege\"\n",
       "  \"δαϕ\" => \"ggg\"\n",
       "  \"Bββ\" => \"egg\"\n",
       "  \"αED\" => \"gee\"\n",
       "  \"DIβ\" => \"eeg\"\n",
       "  \"DCα\" => \"eeg\"\n",
       "  \"δϵα\" => \"ggg\"\n",
       "  \"EBD\" => \"eee\"\n",
       "  \"IEB\" => \"eee\"\n",
       "  \"βCϵ\" => \"geg\"\n",
       "  \"BEI\" => \"eee\"\n",
       "  \"IBB\" => \"eee\"\n",
       "  \"ϕαD\" => \"gge\"\n",
       "  \"DCγ\" => \"eeg\"\n",
       "  \"ϵβC\" => \"gge\"\n",
       "  \"δγδ\" => \"ggg\"\n",
       "  \"βαβ\" => \"ggg\"\n",
       "  ⋮     => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"./side_information_table.jl\")\n",
    "side1_codebook = create_side_information_codebook(sorted_symbols, language_dict)\n",
    "side2_codebook = create_side_information_codebook(block2_codes, language_dict)\n",
    "side3_codebook = create_side_information_codebook(block3_codes, language_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_block1, side_prob1 = side_information_table(sorted_symbols, sorted_probabilities, side1_codebook)\n",
    "side_block2, side_prob2 = side_information_table(block2_codes, prob_block2_codes, side2_codebook)\n",
    "side_block3, side_prob3 = side_information_table(block3_codes, prob_block3_codes, side3_codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "side_2_block    : Dictionary mapping\n",
    "                    Side information block symbols => Block Symbols\n",
    "side_2_block    : Dictionary mapping \n",
    "                    Side information block symbols => Block Symbols' Conditional Probablity\n",
    "\n",
    "Output:\n",
    "unique_trees    : Dictionary mapping\n",
    "                    Side information block symbols => Huffman Tree\n",
    "unique_encoders : Dictionary mapping\n",
    "                    Side information block symbols => Huffman Encoder given Side Information\n",
    "=#\n",
    "function encode_w_side_info(side_2_block, side_2_prob)\n",
    "    unique_trees = Dict();\n",
    "    unique_encoders = Dict(); \n",
    "    for (side_info, conditional_probabilities) in side_2_prob\n",
    "        conditioned_symbol = side_2_block[side_info];\n",
    "        ___, ____, P_dict = sort_prob(conditional_probabilities, conditioned_symbol);\n",
    "        tree = construct_huffman_tree(P_dict);\n",
    "        encoder = Dict();\n",
    "        build_encoder(tree, \"\", encoder);\n",
    "\n",
    "        unique_trees[side_info] = tree;\n",
    "        unique_encoders[side_info] = encoder;\n",
    "    end\n",
    "    return unique_trees, unique_encoders\n",
    "end\n",
    "\n",
    "side_tree1, side_encoder1 = encode_w_side_info(side_block1, side_prob1);\n",
    "side_tree2, side_encoder2 = encode_w_side_info(side_block2, side_prob2);\n",
    "side_tree3, side_encoder3 = encode_w_side_info(side_block3, side_prob3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "side_2_encoder : Dictionary mapping\n",
    "                    Side information block symbols => Codeblock Encoder given Side Information\n",
    "=#\n",
    "function unroll_side_info_encoders(side_2_encoder)\n",
    "    encoder_side_info = Dict();\n",
    "    for (side_info, encoder) in side_2_encoder\n",
    "        merge!(encoder_side_info, encoder)\n",
    "    end\n",
    "\n",
    "    return encoder_side_info\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1b) Huffman Encoder given Side Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_side_encoder1 = unroll_side_info_encoders(side_encoder1);\n",
    "u_side_encoder2 = unroll_side_info_encoders(side_encoder2);\n",
    "u_side_encoder3 = unroll_side_info_encoders(side_encoder3);\n",
    "\n",
    "report_expected_len(u_side_encoder1, P_sorted_dict, 1)\n",
    "report_expected_len(u_side_encoder2, P2_sorted_dict, 2)\n",
    "report_expected_len(u_side_encoder3, P3_sorted_dict, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_side_encoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_huffman(side_tree3[\"ege\"], \"0001101\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Constructing Viterbi Decoder\n",
    "1. First Define the Emission Matrix based on $\\theta_{t}$ & $Z_{t}$\n",
    "2. For Transition Matrix based on $\\theta_{t}$, it is an identity matrix except at $t = n$\n",
    "3. For $t = n$ case, we define another Transition Matrix that has the Source Symbol $X_{0}$ probability properties\n",
    "4. Define the sequence $Z_{0:5} = \"A \\beta \\beta \\beta D D\"$\n",
    "5. Run Viterbi Decoder based on different $n$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "Input:\n",
    "probabilities   : Vector containing probabilities of source\n",
    "ϵ               : Observation Error on observing Hidden State\n",
    "\n",
    "Output:\n",
    "emission_matrix : Emission Matrix describing Hidden State -> Observation State\n",
    "=#\n",
    "function create_emission_matrix(probabilities, ϵ = 0.02)\n",
    "    num_states = length(probabilities);\n",
    "    emission_matrix = zeros(num_states, num_states);\n",
    "\n",
    "    for (row_idx, row) in enumerate(eachrow(emission_matrix))\n",
    "        normalization = (1//1) - probabilities[row_idx];\n",
    "        for (entry_idx, prob) in enumerate(row)\n",
    "            if entry_idx == row_idx\n",
    "                row[entry_idx] = (1 - ϵ); # * P(itself) // P(itself) -> 1\n",
    "            else\n",
    "                row[entry_idx] = ϵ * (probabilities[entry_idx] // normalization)\n",
    "            end\n",
    "        end\n",
    "        # println(\"$row_idx : $row w/ norm = $normalization\")\n",
    "    end\n",
    "\n",
    "    return emission_matrix\n",
    "end\n",
    "\n",
    "#=\n",
    "Used for resetting at t = n\n",
    "Input:\n",
    "probabilities   : Vector containing probabilities of source\n",
    "\n",
    "Output:\n",
    "reset_transition_matrix : Transition Matrix of Hidden States that resets back to Initial Condition\n",
    "=#\n",
    "function source_transition_matrix(probabilities)\n",
    "    num_states = length(probabilities);\n",
    "    reset_transition_matrix = zeros(num_states, num_states);\n",
    "    for (row_idx, row) in enumerate(eachrow(reset_transition_matrix))\n",
    "        reset_transition_matrix[row_idx, :] = probabilities;\n",
    "    end\n",
    "    return reset_transition_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./viterbi.jl\")\n",
    "using LinearAlgebra\n",
    "num_states = length(sorted_probabilities);\n",
    "θ_transition = Matrix(1I, num_states, num_states);\n",
    "Z_sequence = [\"A\", \"β\", \"β\", \"β\", \"D\", \"D\"];\n",
    "ϵ = 0.02;\n",
    "\n",
    "emission_matrix = create_emission_matrix(sorted_probabilities, ϵ);\n",
    "reset_transition_matrix = source_transition_matrix(sorted_probabilities);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x6, T1_6, T2_6 = Viterbi(Z_sequence, θ_transition, emission_matrix,\n",
    "                            sorted_symbols, sorted_symbols, sorted_probabilities,\n",
    "                            reset_transition_matrix, 6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3, T1_3, T2_3 = Viterbi(Z_sequence, θ_transition, emission_matrix,\n",
    "                            sorted_symbols, sorted_symbols, sorted_probabilities,\n",
    "                            reset_transition_matrix, 3);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2b) Compute MAP estimator when $n = 6$ & $n = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Decoded Sequences:\")\n",
    "println(\"For n = 3 => $x3\")\n",
    "println(\"For n = 6 => $x6\")\n",
    "println(\"MAP Probability: \")\n",
    "println(\"For n = 3 => MAP probability =  $(maximum(T1_3[:, 6]))\")\n",
    "println(\"For n = 6 => MAP probability = $(maximum(T1_6[:, 6]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
